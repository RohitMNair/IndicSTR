{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from model.Img2Vec import Img2Vec\n",
    "from model.ResNet import ResNet\n",
    "from model.focalnet import FocalNetBackbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The checkpoint \".ckpt\" path\n",
    "ckpt_path = \"/home/rohitn/D1/Hindi_embed_logs/Img2Vec_FocalNet_wo_B_r256/147196/checkpoints/epoch=7-val_loss=0.41-val_acc=0.77.ckpt\"\n",
    "# give appropriate name for embeddings\n",
    "name = \"focalnet_wo_B_r256.pth\"\n",
    "# save location\n",
    "save_path = Path(\"/home/rohitn/IndianSTR/Img2Vec/GroupNet/embeddings/new\") / name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Backbone\n",
    "refer the checkpoint hydra config to initialize the backbone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ResNet(\n",
    "                    version= 50,\n",
    "                    img_size= 128,\n",
    "                    out_features= 1024,               \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "backbone = FocalNetBackbone(\n",
    "    config = transformers.FocalNetConfig(\n",
    "                  image_size= 128,\n",
    "                  patch_size= 4,\n",
    "                  num_channels= 3,\n",
    "                  embed_dim= 96,\n",
    "                  use_conv_embed= True,\n",
    "                  hidden_sizes= [96,192,384,768],\n",
    "                  depths= [2,2,18,2],\n",
    "                  focal_levels= [2, 2, 2, 2],\n",
    "                  focal_windows= [3, 3, 3, 3],\n",
    "                  hidden_act= \"gelu\",\n",
    "                  mlp_ratio= 4.0,\n",
    "                  hidden_dropout_prob= 0.2,\n",
    "                  drop_path_rate= 0.1,\n",
    "                  use_layerscale= 1.0e-4,\n",
    "                  use_post_layernorm= False,\n",
    "                  use_post_layernorm_in_modulation= False,\n",
    "                  normalize_modulator= False,\n",
    "                  initializer_range= 2.0e-2,\n",
    "                  layer_norm_eps= 1.0e-5,\n",
    "                  encoder_stride= 32,\n",
    "                  out_features= None,\n",
    "              ),\n",
    "            out_features= 768\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize Img2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Img2Vec.load_from_checkpoint(ckpt_path, backbone= backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Img2Vec.load_from_checkpoint(ckpt_path, backbone= backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_c_2_emb = model.half_character2_head.weight.data\n",
    "h_c_1_emb = model.half_character1_head.weight.data\n",
    "f_c_emb = model.character_head.weight.data\n",
    "d_emb = model.diacritic_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([35, 256]),\n",
       " torch.Size([35, 256]),\n",
       " torch.Size([70, 256]),\n",
       " torch.Size([16, 256]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_c_2_emb.shape, h_c_1_emb.shape, f_c_emb.shape, d_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 70, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.half_character_classes), len(model.character_classes), len(model.diacritic_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings along with character classes,\n",
    "# in the embeddings folder of GroupNet\n",
    "torch.save({\n",
    "    \"h_c_2_emb\":h_c_2_emb,\n",
    "    \"h_c_1_emb\":h_c_1_emb,\n",
    "    \"f_c_emb\":f_c_emb,\n",
    "    \"d_emb\":d_emb,\n",
    "    \"h_c_classes\": model.half_character_classes,\n",
    "    \"f_c_classes\": model.character_classes,\n",
    "    \"d_classes\": model.diacritic_classes,\n",
    "    }, \n",
    "    save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = torch.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['h_c_2_emb', 'h_c_1_emb', 'f_c_emb', 'd_emb', 'h_c_classes', 'f_c_classes', 'd_classes'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict[\"h_c_classes\"] == [ 'क', 'ख', 'ग', 'घ', 'ङ',\n",
    "                            'च', 'छ', 'ज', 'झ', 'ञ',\n",
    "                            'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
    "                            'त', 'थ', 'द', 'ध', 'न',\n",
    "                            'प', 'फ', 'ब', 'भ', 'म',\n",
    "                            'य', 'र', 'ल', 'ळ', 'व', 'श',\n",
    "                            'ष', 'स', 'ह']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_dict[\"h_c_classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IndicEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
