_target_: model.PARSeq.net.ViTPARSeq
# encoder args
hidden_size: 384
num_hidden_layers: 12
num_attention_heads: 6
mlp_ratio: 4.0
dropout: 0.0
initializer_range: 0.02
layer_norm_eps: 1.0e-12
image_size: 128
patch_size: 8
num_channels: 3
# decoder args
dec_num_sa_heads: [[2,2], 4, [2,2]]
dec_num_ca_heads: 12
dec_mlp_ratio: 4
dec_depth: 1
perm_num: 25
perm_forward: True
perm_mirrored: True
decode_ar: True
refine_iters: 1
# tokenizer args
tokenizer: HindiPARSeqTokenizer
threshold: 0.5
max_grps: 25
# training args
learning_rate: 1.0e-4
weight_decay: 1.0e-4
warmup_pct: 0.3
                 